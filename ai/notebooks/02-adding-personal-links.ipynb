{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:10.853271Z",
     "start_time": "2025-05-19T14:06:10.804533Z"
    }
   },
   "cell_type": "code",
   "source": "#!pip install pymongo requests python-dotenv tqm",
   "id": "19326a231ffbb83e",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:11.362232Z",
     "start_time": "2025-05-19T14:06:11.103240Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from pymongo import MongoClient\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse\n",
    "from transformers import pipeline\n",
    "import re\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from transformers.utils import logging\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime"
   ],
   "id": "initial_id",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:11.614968Z",
     "start_time": "2025-05-19T14:06:11.400097Z"
    }
   },
   "cell_type": "code",
   "source": [
    "load_dotenv()\n",
    "\n",
    "mongo_host = os.getenv('MONGO_HOST')\n",
    "mongo_port = os.getenv('MONGO_PORT')\n",
    "mongo_db = os.getenv('MONGO_DB')\n",
    "mongo_collection = os.getenv('MONGO_COLLECTION')\n",
    "\n",
    "github_token = os.getenv('GITHUB_TOKEN')"
   ],
   "id": "e9f58e2066bf9dcf",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:12.050842Z",
     "start_time": "2025-05-19T14:06:11.645197Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import os\n",
    "from pymongo import MongoClient\n",
    "\n",
    "mongo_host = os.getenv(\"MONGO_HOST\", \"localhost\")\n",
    "mongo_port = int(os.getenv(\"MONGO_PORT\", 27017))\n",
    "mongo_db = os.getenv(\"MONGO_DB\", \"PFE\")  # valeur par défaut\n",
    "mongo_collection = os.getenv(\"MONGO_COLLECTION\", \"resumes\")  # valeur par défaut\n",
    "\n",
    "client = MongoClient(\n",
    "    host=mongo_host,\n",
    "    port=mongo_port,\n",
    "    serverSelectionTimeoutMS=2000,\n",
    "    connectTimeoutMS=10000,\n",
    "    socketTimeoutMS=10000\n",
    ")\n",
    "\n",
    "try:\n",
    "    client.admin.command(\"ping\")\n",
    "except Exception as e:\n",
    "    raise RuntimeError(f\"MongoDB non accessible: {e}\")\n",
    "\n",
    "db = client[mongo_db]\n",
    "resumes_collection = db[mongo_collection]\n"
   ],
   "id": "ba7f5a1a5e08fdd3",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:15.007246Z",
     "start_time": "2025-05-19T14:06:12.156895Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Load summarization model (local inference)\n",
    "logging.set_verbosity_error()\n",
    "summarizer = pipeline(\"summarization\", model=\"pszemraj/led-base-book-summary\", tokenizer=\"pszemraj/led-base-book-summary\")"
   ],
   "id": "b9e11bd855436c7f",
   "outputs": [],
   "execution_count": 16
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:15.046459Z",
     "start_time": "2025-05-19T14:06:15.036147Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def clean_markdown(text):\n",
    "    # Remove badges (e.g., ![alt](...) or <img ...>)\n",
    "    text = re.sub(r'!\\[.*?\\]\\(.*?\\)', '', text)\n",
    "    text = re.sub(r'<img.*?>', '', text)\n",
    "\n",
    "    # Remove raw HTML tags\n",
    "    text = BeautifulSoup(text, \"html.parser\").get_text()\n",
    "\n",
    "    # Remove code blocks (```...```)\n",
    "    text = re.sub(r'```.*?```', '', text, flags=re.DOTALL)\n",
    "\n",
    "    # Remove inline code (`...`)\n",
    "    text = re.sub(r'`[^`]+`', '', text)\n",
    "\n",
    "    # Remove markdown links but keep the link text\n",
    "    text = re.sub(r'\\[([^\\]]+)\\]\\([^)]+\\)', r'\\1', text)\n",
    "\n",
    "    # Remove headings (e.g., # Heading)\n",
    "    text = re.sub(r'^#+\\s+', '', text, flags=re.MULTILINE)\n",
    "\n",
    "    # Remove excess whitespace\n",
    "    text = re.sub(r'\\n{2,}', '\\n\\n', text)\n",
    "    text = re.sub(r'[ \\t]+', ' ', text)\n",
    "\n",
    "    return text.strip()"
   ],
   "id": "f93be0e073fc7ffd",
   "outputs": [],
   "execution_count": 17
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:15.089031Z",
     "start_time": "2025-05-19T14:06:15.073079Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def get_readme_content(github_readme_url):\n",
    "    # Convert to raw content URL\n",
    "    if \"github.com\" in github_readme_url and \"blob\" in github_readme_url:\n",
    "        raw_url = github_readme_url.replace(\"github.com\", \"raw.githubusercontent.com\").replace(\"/blob\", \"\")\n",
    "    else:\n",
    "        raw_url = github_readme_url  # assume it's already raw\n",
    "\n",
    "    try:\n",
    "        readme_resp = requests.get(raw_url)\n",
    "        readme_resp.raise_for_status()\n",
    "        return clean_markdown(readme_resp.text)\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return None"
   ],
   "id": "425d42c02166116d",
   "outputs": [],
   "execution_count": 18
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:15.152573Z",
     "start_time": "2025-05-19T14:06:15.117371Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def extract_github_projects(profile_url, token=None, existing_repo_names=None):\n",
    "    username = urlparse(profile_url).path.strip(\"/\").split(\"/\")[0]\n",
    "    headers = {\"Accept\": \"application/vnd.github+json\"}\n",
    "    repos_url = f\"https://api.github.com/users/{username}/repos\"\n",
    "    if token:\n",
    "        headers[\"Authorization\"] = f\"Bearer {token}\"\n",
    "\n",
    "    existing_repo_names = {name.lower() for name in (existing_repo_names or [])}\n",
    "\n",
    "    try:\n",
    "        response = requests.get(repos_url, headers=headers)\n",
    "        response.raise_for_status()\n",
    "        repos = response.json()\n",
    "        projects = []\n",
    "\n",
    "        for repo in repos:\n",
    "            repo_name = repo[\"name\"]\n",
    "\n",
    "            # Skip already existing repos\n",
    "            if repo_name.lower() in existing_repo_names:\n",
    "                print(f\"repo {repo_name} already exists, skipping\")\n",
    "                continue\n",
    "\n",
    "            print(f\"processing repo {repo_name}\")\n",
    "\n",
    "            repo_url = repo[\"html_url\"]\n",
    "            description = repo[\"description\"]\n",
    "\n",
    "            langs_url = f\"https://api.github.com/repos/{username}/{repo_name}/languages\"\n",
    "            langs_resp = requests.get(langs_url, headers=headers)\n",
    "            all_languages = list(langs_resp.json().keys()) if langs_resp.status_code == 200 else []\n",
    "\n",
    "            readme_url = f\"https://github.com/{username}/{repo_name}/blob/main/README.md\"\n",
    "            readme_resp = requests.get(readme_url)\n",
    "\n",
    "            if readme_resp.status_code != 200:\n",
    "                readme_url = f\"https://github.com/{username}/{repo_name}/blob/master/README.md\"\n",
    "                readme_resp = requests.get(readme_url)\n",
    "\n",
    "            summary = None\n",
    "            if readme_resp.status_code == 200:\n",
    "                try:\n",
    "                    content = get_readme_content(readme_url)\n",
    "                    input_length = len(summarizer.tokenizer.encode(content))\n",
    "                    max_length = min(200, int(input_length * 0.8)) if input_length > 30 else 40\n",
    "                    summary = summarizer(content, max_length=max_length, min_length=30, do_sample=False)[0]['summary_text']\n",
    "                except Exception:\n",
    "                    summary = None\n",
    "\n",
    "            project = {\n",
    "                \"repo_name\": repo_name,\n",
    "                \"description\": summary or description,\n",
    "                \"url\": repo_url,\n",
    "                \"languages\": all_languages\n",
    "            }\n",
    "\n",
    "            if all_languages:\n",
    "                projects.append(project)\n",
    "\n",
    "        return {\"github_projects\": projects}\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"Error fetching GitHub repos for {username}: {e}\")\n",
    "        return {\"github_projects\": []}"
   ],
   "id": "d176bf44acdc38ef",
   "outputs": [],
   "execution_count": 19
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:06:15.196098Z",
     "start_time": "2025-05-19T14:06:15.177390Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def update_resumes_with_github_projects():\n",
    "    resumes = list(resumes_collection.find({\n",
    "        \"personal_links.github\": {\"$exists\": True, \"$ne\": None}\n",
    "    }))\n",
    "\n",
    "    for resume in tqdm(resumes, desc=\"Updating resumes\"):\n",
    "        github_url = resume[\"personal_links\"][\"github\"]\n",
    "\n",
    "        # Ensure the URL starts with https://\n",
    "        if not github_url.startswith(\"http\"):\n",
    "            github_url = \"https://\" + github_url\n",
    "\n",
    "        print(f\"\\nProcessing resume: {resume.get('_id')} | GitHub: {github_url}\")\n",
    "\n",
    "        existing_projects = resume.get(\"github_projects\", [])\n",
    "\n",
    "        existing_names = {proj[\"repo_name\"].lower() for proj in existing_projects}\n",
    "\n",
    "        extracted = extract_github_projects(github_url, token=github_token, existing_repo_names=existing_names)\n",
    "\n",
    "        new_projects = extracted.get(\"github_projects\", [])\n",
    "\n",
    "        # Update if needed\n",
    "        if new_projects:\n",
    "            updated_projects = existing_projects + new_projects\n",
    "            resumes_collection.update_one(\n",
    "                {\"_id\": resume[\"_id\"]},\n",
    "                {\n",
    "                    \"$set\": {\n",
    "                        \"github_projects\": updated_projects,\n",
    "                        \"last_updated\": datetime.utcnow()\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "            print(f\"→ Updated with {len(new_projects)} new project(s).\")\n",
    "        else:\n",
    "            print(\"→ No new projects to add.\")"
   ],
   "id": "b177d86fc74aaf3e",
   "outputs": [],
   "execution_count": 20
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:22:26.662659Z",
     "start_time": "2025-05-19T14:06:15.226595Z"
    }
   },
   "cell_type": "code",
   "source": "update_resumes_with_github_projects()",
   "id": "f9904efa0e4257b",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:   0%|          | 0/16 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing resume: 6816e2308c095f364cfca340 | GitHub: https://github.com/ExtremelySunnyYK\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:   6%|▋         | 1/16 [00:00<00:05,  2.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for ExtremelySunnyYK: 404 Client Error: Not Found for url: https://api.github.com/users/ExtremelySunnyYK/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 68175c842d7cc10ceb81604e | GitHub: https://github.com/ashlylau\n",
      "processing repo adversarial-robustness-toolbox\n",
      "processing repo archive-website\n",
      "processing repo ashlylau.github.io\n",
      "processing repo bg-anim\n",
      "processing repo bootstrap-test\n",
      "processing repo C-Lexis-Tests\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AzComputer\\PyCharmMiscProject\\.venv\\Lib\\site-packages\\transformers\\generation\\utils.py:1570: UserWarning: Unfeasible length constraints: `min_length` (30) is larger than the maximum possible length (26). Generation will stop at the defined maximum length. You should decrease the minimum length and/or increase the maximum length.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing repo Camera-Application\n",
      "processing repo co362-group1\n",
      "processing repo deep-income\n",
      "processing repo facebook-H-A-P\n",
      "processing repo First-Android-App\n",
      "processing repo first-website\n",
      "processing repo Flare-Flutter\n",
      "processing repo google-challenges-practice\n",
      "processing repo Handcrafted-DP\n",
      "processing repo HatchHack-Team2\n",
      "processing repo hatchlondon-2017-projects\n",
      "processing repo health-hack-20\n",
      "processing repo hole-in-the-wall\n",
      "processing repo hole-in-the-wall-archive\n",
      "processing repo internship-coding-challenge-2019\n",
      "processing repo intro-to-ml-repo\n",
      "processing repo judge-pet\n",
      "processing repo mixup-cifar10\n",
      "processing repo ml-class\n",
      "processing repo NHANES-diabetes\n",
      "processing repo private-data-generation\n",
      "processing repo private-pipelines\n",
      "processing repo pygame-tutorial\n",
      "processing repo PyStatDP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AzComputer\\AppData\\Local\\Temp\\ipykernel_19396\\497628203.py:31: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  \"last_updated\": datetime.utcnow()\n",
      "Updating resumes:  12%|█▎        | 2/16 [05:14<43:12, 185.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 29 new project(s).\n",
      "\n",
      "Processing resume: 68175d692d7cc10ceb816050 | GitHub: https://github.com/AnuvaGoyal\n",
      "processing repo FACE-MASK-DETECTION\n",
      "processing repo Heart-Attack-Prediction\n",
      "processing repo LDA-Topic-Modeling\n",
      "processing repo Mental-Healthcare-Chatbot\n",
      "processing repo TECH-A-THON-Emotion-Based-Movie-Recommender-System\n",
      "processing repo Web-Scraping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  19%|█▉        | 3/16 [06:40<30:18, 139.87s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 6 new project(s).\n",
      "\n",
      "Processing resume: 68175e0a2d7cc10ceb816051 | GitHub: https://github.com/AnuvaGoyal\n",
      "processing repo FACE-MASK-DETECTION\n",
      "processing repo Heart-Attack-Prediction\n",
      "processing repo LDA-Topic-Modeling\n",
      "processing repo Mental-Healthcare-Chatbot\n",
      "processing repo TECH-A-THON-Emotion-Based-Movie-Recommender-System\n",
      "processing repo Web-Scraping\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  25%|██▌       | 4/16 [08:06<23:40, 118.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 6 new project(s).\n",
      "\n",
      "Processing resume: 6817625e2d7cc10ceb816053 | GitHub: https://github.com/aswathinrp\n",
      "processing repo AD-Click-Predictions\n",
      "processing repo aswathi\n",
      "processing repo aswathinrp\n",
      "processing repo bg_removal\n",
      "processing repo CarPricePrediction-Flask-app\n",
      "processing repo clone-microsoft\n",
      "processing repo Driver-drowsiness-project\n",
      "processing repo facedetection-harcascade\n",
      "processing repo Facemask-detection\n",
      "processing repo forest_fire-prediction\n",
      "processing repo HandgestureRecognition\n",
      "processing repo hello_world\n",
      "processing repo image_summarisation-with-openai\n",
      "processing repo interaction-with-db-tables\n",
      "processing repo login-home-page-using-python-django\n",
      "processing repo Movie-Recommendations-Using-Machine-Learning---Streamlit\n",
      "processing repo ms-clone\n",
      "processing repo mybudgethouse\n",
      "processing repo name-generator\n",
      "processing repo Netflix\n",
      "processing repo netflix-responsive\n",
      "processing repo NumberplateDetection\n",
      "processing repo object-detection-using-mobilenet-SSD\n",
      "processing repo object-detection-using-SSD\n",
      "processing repo open_cv\n",
      "processing repo parrot_detection_using-yolov5\n",
      "processing repo pdf-e-sign-with-python\n",
      "processing repo pdf-esign-application\n",
      "processing repo Pencil-Drawing---cv2\n",
      "processing repo personalsite\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  31%|███▏      | 5/16 [09:39<20:00, 109.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 23 new project(s).\n",
      "\n",
      "Processing resume: 681763012d7cc10ceb816055 | GitHub: https://github.com/Fulkar-khan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  38%|███▊      | 6/16 [09:39<12:01, 72.16s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for Fulkar-khan: 404 Client Error: Not Found for url: https://api.github.com/users/Fulkar-khan/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 681763fc2d7cc10ceb816057 | GitHub: https://github.com/KunikaBhargav\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  44%|████▍     | 7/16 [09:39<07:18, 48.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for KunikaBhargav: 404 Client Error: Not Found for url: https://api.github.com/users/KunikaBhargav/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 6817649a2d7cc10ceb816058 | GitHub: https://github.com/kyotikhan\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  50%|█████     | 8/16 [09:40<04:26, 33.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for kyotikhan: 404 Client Error: Not Found for url: https://api.github.com/users/kyotikhan/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 681764f32d7cc10ceb816059 | GitHub: https://github.com/ToshanTile\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  56%|█████▋    | 9/16 [09:40<02:40, 22.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for ToshanTile: 404 Client Error: Not Found for url: https://api.github.com/users/ToshanTile/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 681766372d7cc10ceb81605b | GitHub: https://github.com/AnmishaMurarka\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  62%|██████▎   | 10/16 [09:40<01:35, 15.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for AnmishaMurarka: 404 Client Error: Not Found for url: https://api.github.com/users/AnmishaMurarka/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 681766e72d7cc10ceb81605c | GitHub: https://phy-m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  69%|██████▉   | 11/16 [09:40<00:55, 11.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for : 404 Client Error: Not Found for url: https://api.github.com/users//repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 681b6f745416ebae9d37160d | GitHub: https://\n",
      "Error fetching GitHub repos for : 404 Client Error: Not Found for url: https://api.github.com/users//repos\n",
      "→ No new projects to add.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  75%|███████▌  | 12/16 [09:41<00:31,  7.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing resume: 681b6fed5416ebae9d37160e | GitHub: https://github.com/KuruvaNagaraju/DataScience\n",
      "processing repo DATA-SCIENCE\n",
      "processing repo DataScience\n",
      "processing repo Nagaraju\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  81%|████████▏ | 13/16 [10:08<00:41, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 2 new project(s).\n",
      "\n",
      "Processing resume: 681b71645416ebae9d371610 | GitHub: https://github.com/gkapil801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  88%|████████▊ | 14/16 [10:09<00:19,  9.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error fetching GitHub repos for gkapil801: 404 Client Error: Not Found for url: https://api.github.com/users/gkapil801/repos\n",
      "→ No new projects to add.\n",
      "\n",
      "Processing resume: 681b75995416ebae9d371612 | GitHub: https://github.com/dhaferalmakhles\n",
      "processing repo dhaferalmakhles.github.io\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes:  94%|█████████▍| 15/16 [10:24<00:11, 11.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 1 new project(s).\n",
      "\n",
      "Processing resume: 681b77195416ebae9d371615 | GitHub: https://github.com/shahidmumtaz\n",
      "processing repo -Shahid\n",
      "processing repo A_Sentiment_analysis\n",
      "processing repo belly_button\n",
      "processing repo BootCampUCD.github.io\n",
      "processing repo CitiBike_Tableau\n",
      "processing repo COVID-19-Socio_Economic_Analysis-Project\n",
      "processing repo D3_challenge\n",
      "processing repo IMDB_Movie_Analysis-Project\n",
      "processing repo javascript_challenge\n",
      "processing repo leaflet_challenge\n",
      "processing repo Matplotlib\n",
      "processing repo Pandas_Challenge\n",
      "processing repo Pet_Pals\n",
      "processing repo Plotly-HW\n",
      "processing repo Predictive-Analysis\n",
      "processing repo project_2\n",
      "processing repo Python-Homework\n",
      "processing repo Python_API\n",
      "processing repo python_challenge\n",
      "processing repo Scientific-Decision-Making\n",
      "processing repo Shahidmumtaz\n",
      "processing repo Shahidmumtaz.github.io\n",
      "processing repo Shark_tank_ETL\n",
      "processing repo sqlalchemy_challenge\n",
      "processing repo sql_challenge\n",
      "processing repo Understanding-Visualizing-data\n",
      "processing repo web-scraping-challenge\n",
      "processing repo Webdesign_challenge\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Updating resumes: 100%|██████████| 16/16 [16:11<00:00, 60.70s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Updated with 20 new project(s).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 21
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:22:26.846914Z",
     "start_time": "2025-05-19T14:22:26.825711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Mongo host:\", mongo_host)\n",
    "print(\"Mongo port:\", mongo_port)\n",
    "print(\"Mongo DB:\", mongo_db)\n",
    "print(\"Mongo collection:\", mongo_collection)\n",
    "print(\"Resumes collection is None:\", resumes_collection is None)\n"
   ],
   "id": "1585e449abc47d2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mongo host: localhost\n",
      "Mongo port: 27017\n",
      "Mongo DB: PFE\n",
      "Mongo collection: resumes\n",
      "Resumes collection is None: False\n"
     ]
    }
   ],
   "execution_count": 22
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-19T14:22:27.086323Z",
     "start_time": "2025-05-19T14:22:27.079832Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "669912a0063633be",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
