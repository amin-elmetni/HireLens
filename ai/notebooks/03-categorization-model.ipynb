{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ==================== 1. IMPORTATION DES BIBLIOTHEQUES ====================\n",
    "import pandas as pd\n",
    "import ast\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, classification_report\n",
    "from transformers import BertTokenizer, BertForSequenceClassification\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.optim import AdamW\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 2. CHARGEMENT ET EXPLORATION DES DONNEES ====================\n",
    "# Chargement du dataset\n",
    "data = pd.read_csv('datasets/categorization-dataset/enhanced_multilabel_resumes.csv')\n",
    "\n",
    "# Conversion des catégories (stockées comme strings) en listes\n",
    "data['Categories'] = data['Categories'].apply(ast.literal_eval)\n",
    "\n",
    "# Analyse de la distribution des catégories\n",
    "all_categories = [category for sublist in data['Categories'] for category in sublist]\n",
    "category_counts = pd.Series(all_categories).value_counts()\n",
    "\n",
    "print(\"Distribution des catégories:\")\n",
    "print(category_counts)\n",
    "category_counts.plot(kind='bar', figsize=(12, 6))\n",
    "plt.title('Distribution des Catégories')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Extraction des textes et labels\n",
    "texts = data['cleaned_resume'].tolist()\n",
    "categories = data['Categories'].tolist()\n"
   ],
   "id": "e6c1cca557fd9929"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 3. PREPROCESSING ET PREPARATION DES DONNEES ====================\n",
    "# Encodage multilabel des catégories\n",
    "mlb = MultiLabelBinarizer()\n",
    "binary_labels = mlb.fit_transform(categories)\n",
    "\n",
    "# Division des données (train: 90%, val: 5%, test: 5%)\n",
    "train_texts, test_texts, train_labels, test_labels = train_test_split(\n",
    "    texts, binary_labels, test_size=0.1, random_state=42\n",
    ")\n",
    "val_texts, test_texts, val_labels, test_labels = train_test_split(\n",
    "    test_texts, test_labels, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Initialisation du tokenizer BERT\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "def tokenize_texts(texts):\n",
    "    # Vérification et conversion en strings\n",
    "    texts = [str(text) for text in texts]\n",
    "    return tokenizer(texts, truncation=True, padding=True, max_length=512, return_tensors=\"pt\")\n",
    "\n",
    "# Nettoyage des textes (remplacement des valeurs None/NaN)\n",
    "train_texts = [text if text is not None and not pd.isna(text) else \"\" for text in train_texts]\n",
    "val_texts = [text if text is not None and not pd.isna(text) else \"\" for text in val_texts]\n",
    "test_texts = [text if text is not None and not pd.isna(text) else \"\" for text in test_texts]\n",
    "\n",
    "# Tokenization des ensembles de données\n",
    "train_encodings = tokenize_texts(train_texts)\n",
    "val_encodings = tokenize_texts(val_texts)\n",
    "test_encodings = tokenize_texts(test_texts)\n"
   ],
   "id": "89587aaf7b0cb265"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 4. CREATION DES DATASETS ET DATALOADERS ====================\n",
    "class CVDataset(Dataset):\n",
    "    def __init__(self, encodings, labels=None):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        if self.labels is not None:\n",
    "            item['labels'] = torch.tensor(self.labels[idx], dtype=torch.float)\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.encodings['input_ids'])\n",
    "\n",
    "# Création des datasets\n",
    "train_dataset = CVDataset(train_encodings, train_labels)\n",
    "val_dataset = CVDataset(val_encodings, val_labels)\n",
    "test_dataset = CVDataset(test_encodings, test_labels)\n",
    "\n",
    "# Création des dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n"
   ],
   "id": "236cdd2d0b002db3"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 5. CONFIGURATION DU MODELE ====================\n",
    "# Chargement du modèle BERT pour classification multilabel\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    'bert-base-uncased',\n",
    "    num_labels=len(mlb.classes_),\n",
    "    problem_type=\"multi_label_classification\"\n",
    ")\n",
    "\n",
    "# Configuration de l'optimiseur et fonction de perte\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "# Déplacement du modèle sur le device approprié (GPU si disponible)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "print(f\"Utilisation du device : {device}\")\n",
    "model.to(device)\n"
   ],
   "id": "d2a62b5ea8c58a54"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 6. ENTRAINEMENT DU MODELE ====================\n",
    "epochs = 10\n",
    "best_val_loss = float('inf')\n",
    "patience = 2\n",
    "early_stopping_counter = 0\n",
    "\n",
    "def compute_metrics(preds, labels, threshold=0.5):\n",
    "    # Conversion des logits en prédictions binaires\n",
    "    preds = (torch.sigmoid(torch.tensor(preds)) > threshold).int().numpy()\n",
    "\n",
    "    # Calcul des métriques\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    precision = precision_score(labels, preds, average='micro')\n",
    "    recall = recall_score(labels, preds, average='micro')\n",
    "\n",
    "    return f1, precision, recall\n",
    "\n",
    "# Boucle d'entraînement principale\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Époque {epoch + 1}/{epochs}\")\n",
    "\n",
    "    # Phase d'entraînement\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for batch in tqdm(train_loader, desc=\"Training\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss /= len(train_loader)\n",
    "\n",
    "    # Phase de validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    val_preds = []\n",
    "    val_labels_list = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=\"Validation\"):\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            val_preds.extend(logits.cpu().numpy())\n",
    "            val_labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "    val_loss /= len(val_loader)\n",
    "\n",
    "    # Calcul et affichage des métriques\n",
    "    f1, precision, recall = compute_metrics(val_preds, val_labels_list)\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "    print(f\"F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "    # Gestion de l'early stopping\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        early_stopping_counter = 0\n",
    "        # Sauvegarde du meilleur modèle\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        early_stopping_counter += 1\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping déclenché !\")\n",
    "            break\n"
   ],
   "id": "8d6c3dc2426df972"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 7. EVALUATION DU MODELE ====================\n",
    "# Chargement du meilleur modèle\n",
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "\n",
    "# Évaluation sur l'ensemble de test\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        test_preds.extend(logits.cpu().numpy())\n",
    "        test_labels_list.extend(labels.cpu().numpy())\n",
    "\n",
    "# Calcul et affichage des métriques\n",
    "f1, precision, recall = compute_metrics(test_preds, test_labels_list)\n",
    "print(\"\\nRésultats sur l'ensemble de test:\")\n",
    "print(f\"F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "test_preds_binary = (torch.sigmoid(torch.tensor(test_preds)) > 0.5).int().numpy()\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(test_labels_list, test_preds_binary, target_names=mlb.classes_, zero_division=0))\n",
    "\n"
   ],
   "id": "e18b6d2ce3c05fd0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# ==================== 8. SAUVEGARDE DES RESULTATS ====================\n",
    "# Sauvegarde du modèle et du tokenizer\n",
    "model_save_path = '/kaggle/working/mon_modele_bert_multilabel'\n",
    "model.save_pretrained(model_save_path)\n",
    "tokenizer.save_pretrained(model_save_path)\n",
    "print(f\"\\nModèle et tokenizer sauvegardés à : {model_save_path}\")\n",
    "\n",
    "# Sauvegarde du MultiLabelBinarizer\n",
    "import joblib\n",
    "joblib.dump(mlb, 'models/multilabel_binarizer.pkl')\n",
    "print(\"MultiLabelBinarizer sauvegardé\")"
   ],
   "id": "21760a12cf824ae5"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "\n",
    "# ==================== 9.Évaluation sur l'ensemble de test ====================\n",
    "model.eval()\n",
    "test_preds = []\n",
    "test_labels_list = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Testing\"):\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        test_preds.append(logits.cpu().numpy())\n",
    "        test_labels_list.append(labels.cpu().numpy())\n",
    "\n",
    "# Convertir les listes en tableaux numpy\n",
    "test_preds = np.concatenate(test_preds, axis=0)\n",
    "test_labels_list = np.concatenate(test_labels_list, axis=0)\n",
    "\n",
    "# Calcul des métriques sur le test\n",
    "def compute_metrics(preds, labels, threshold=0.5):\n",
    "    # Convertir les logits en prédictions binaires\n",
    "    preds = (torch.sigmoid(torch.tensor(preds)) > threshold).int().numpy()\n",
    "\n",
    "    # Calculer les métriques\n",
    "    f1 = f1_score(labels, preds, average='micro')\n",
    "    precision = precision_score(labels, preds, average='micro')\n",
    "    recall = recall_score(labels, preds, average='micro')\n",
    "\n",
    "    return f1, precision, recall, preds\n",
    "\n",
    "f1, precision, recall, test_preds_binary = compute_metrics(test_preds, test_labels_list)\n",
    "\n",
    "print(\"\\nRésultats sur l'ensemble de test:\")\n",
    "print(f\"F1: {f1:.4f}, Precision: {precision:.4f}, Recall: {recall:.4f}\")\n",
    "\n",
    "# Rapport de classification détaillé\n",
    "print(\"\\nRapport de classification:\")\n",
    "print(classification_report(test_labels_list, test_preds_binary, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "# Affichage de quelques exemples de prédictions\n",
    "print(\"\\nExemples de prédictions:\")\n",
    "num_examples = 50\n",
    "for i in range(num_examples):\n",
    "    print(f\"\\nExemple {i+1}:\")\n",
    "    print(f\"Texte: {test_texts[i][:100]}...\")  # Affiche les 100 premiers caractères\n",
    "    print(f\"Labels réels: {[mlb.classes_[i] for i, val in enumerate(test_labels_list[i]) if val == 1]}\")\n",
    "    print(f\"Labels prédits: {[mlb.classes_[i] for i, val in enumerate(test_preds_binary[i]) if val == 1]}\")"
   ],
   "id": "6362a1fd9fe5155e"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
